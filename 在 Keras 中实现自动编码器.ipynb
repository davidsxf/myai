{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动编码器\n",
    "正如您在介绍中读到的，自动编码器是一种无监督机器学习算法，它将图像作为输入，并尝试使用瓶颈（也称为潜在空间）中较少的位数重建图像。图像主要在瓶颈处被压缩。自动编码器中的压缩是通过对网络进行一段时间的训练来实现的，并且在学习过程中，它会尝试在瓶颈处最好地表示输入图像。JPEG 和 JPEG 无损压缩技术等通用图像压缩算法无需任何类型的训练即可压缩图像，并且在压缩图像方面表现相当不错。\n",
    "\n",
    "自动编码器类似于主成分分析 (PCA) 等降维技术。它​​们使用线性变换将数据从高维投影到低维，并尝试保留数据的重要特征，同时删除非必要部分。\n",
    "\n",
    "然而，自动编码器和 PCA 之间的主要区别在于转换部分：正如您已经读到的，PCA 使用线性变换，而自动编码器使用非线性变换。\n",
    "\n",
    "现在您对自动编码器有了一定的了解，让我们来分解这个术语并尝试对它有一些直觉！\n",
    "https://www.datacamp.com/tutorial/autoencoder-keras-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522830223/Autoencoder_structure_af1jh8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动编码器可以分为三个部分\n",
    "\n",
    "编码器：网络的这一部分将输入压缩或下采样为更少的位数。这些更少的位数所代表的空间通常称为潜在空间或瓶颈。瓶颈也称为“最大压缩点”，因为此时输入被最大程度地压缩。这些代表原始输入的压缩位统称为输入的“编码”。\n",
    "解码器：网络的这一部分尝试仅使用输入的编码来重建输入。当解码器能够完全按照输入到编码器的方式重建输入时，可以说编码器能够为输入生成最佳编码，解码器能够很好地重建输入！\n",
    "自动编码器有很多种，例如卷积自动编码器、去噪自动编码器、变分自动编码器和稀疏自动编码器。但是，正如您在介绍中读到的那样，您将只关注本教程中的卷积和去噪自动编码器。使用 Keras 在 Python 中实现卷积自动编码器\n",
    "\n",
    "由于输入数据由图像组成，因此使用卷积自动编码器是个好主意。它不是自动编码器的变体，而是堆叠了卷积层的传统自动编码器：基本上是用卷积层替换全连接层。卷积层与最大池化层一起将输入从宽（28 x 28 图像）和薄（单通道或灰度）转换为小（潜在空间中的 7 x 7 图像）和厚（128 通道）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这有助于网络从图像中提取视觉特征，从而获得更准确的潜在空间表示。重建过程使用上采样和卷积，称为解码器。下采样是将图像压缩为低维度的过程，也称为编码器。\n",
    "\n",
    "值得注意的是，编码器主要压缩输入图像，例如：如果您的输入图像尺寸为 176 x 176 x 1 (~30976)，则最大压缩点的尺寸可以是 22 x 22 x 512 (~247808)。因此，在这种情况下，您从尺寸为 176 x 176 的灰度图像开始，并通过几个卷积层和三个最大池化层，您的图像最终被下采样为尺寸为 22 x 22，但通道数从 1 增加到 512。如上所述，您的输入从宽（176 x 176）和薄（1）变为小（22x22）和厚（512）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据\n",
    "notMNIST 数据集是字母 A 到 J 的字体字形的图像识别数据集。它与经典的MNIST数据集非常相似，后者包含手写数字 0 到 9 的图像：在这种情况下，您会发现 NotMNIST 数据集包含 28x28 灰度图像，共 70,000 个字母，从 A 到 J，分为 10 个类别，每个类别 6,000 张图像。\n",
    "\n",
    "提示：如果您想了解如何使用 MNIST 数据集实现多层感知器 (MLP) 进行分类任务，请查看本教程。\n",
    "\n",
    "NotMNIST 数据集未在 Keras 或 TensorFlow 框架中预定义，因此您必须从此来源下载数据。数据将以ubyte.gzip格式下载，但目前无需担心！您很快就会学习如何读取字节流格式并将其转换为 NumPy 数组。那么，让我们开始吧！\n",
    "\n",
    "该网络将在 Nvidia Tesla K40 上进行训练，因此如果您在 GPU 上训练并使用 Jupyter Notebook，则需要添加三行代码，其中使用名为的模块指定 CUDA 设备顺序和 CUDA 可见设备os。\n",
    "\n",
    "在下面的代码中，您基本上使用 在笔记本中设置环境变量os.environ。在初始化 Keras 之前，最好执行以下操作以限制 Keras 后端 TensorFlow 使用第一个 GPU。如果您训练的机器上的 GPU 是0，请确保使用0而不是1。您可以通过在终端上运行一个简单的命令来检查：例如，nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，您定义一个函数来打开gzip文件，使用 读取文件bytestream.read()。您将图像尺寸和图像总数传递给此函数。然后，使用np.frombuffer()将存储在变量中的字符串转换buf为 类型的 NumPy 数组float32。\n",
    "\n",
    "接下来，将数组重塑为三维数组或张量，其中第一维是图像数量，第二维和第三维是图像的维度。最后，返回 NumPy 数组data。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28, 28)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('../data/train-images-idx3-ubyte.gz', 60000)\n",
    "test_data = extract_data('../data/t10k-images-idx3-ubyte.gz', 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = extract_labels('../data/train-labels-idx1-ubyte.gz', 60000)\n",
    "test_labels = extract_labels('../data/t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (60000, 28, 28)\n",
      "Test set (images) shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'A',\n",
    " 1: 'B',\n",
    " 2: 'C',\n",
    " 3: 'D',\n",
    " 4: 'E',\n",
    " 5: 'F',\n",
    " 6: 'G',\n",
    " 7: 'H',\n",
    " 8: 'I',\n",
    " 9: 'J',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: D)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5, 5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[0], (28, 28))\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_data[0], (28, 28))\n",
    "curr_lbl = test_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28, 28, 1)\n",
    "test_data = test_data.reshape(-1, 28, 28, 1)\n",
    "train_data.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtype, test_data.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255.0, 255.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_ground, valid_ground = train_test_split(train_data,\n",
    "                                                                train_data,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape=(x, y, inChannel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如前所述，自动编码器分为两个部分：编码器和解码器。\n",
    "\n",
    "编码器\n",
    "\n",
    "第一层有 32 个 3 x 3 大小的过滤器，后面跟着一个下采样（最大池化）层，\n",
    "第二层将有 64 个大小为 3 x 3 的过滤器，后面跟着另一个下采样层，\n",
    "编码器的最后一层将有 128 个大小为 3 x 3 的过滤器。\n",
    "\n",
    "\n",
    "解码器\n",
    "\n",
    "第一层将有 128 个大小为 3 x 3 的过滤器，后面跟着一个上采样层，/li>\n",
    "第二层将有 64 个大小为 3 x 3 的过滤器，后面紧接着另一个上采样层，\n",
    "编码器的最后一层将有 1 个大小为 3 x 3 的过滤器。\n",
    "每次使用时，最大池化层都会将输入下采样两倍，而每次使用时，上采样层都会将输入上采样两倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    # encoder\n",
    "    # input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu',\n",
    "                   padding='same')(input_img)  # 28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)  # 14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu',\n",
    "                   padding='same')(pool1)  # 14 x 14 x 64\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)  # 7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(\n",
    "        pool2)  # 7 x 7 x 128 (small and thick)\n",
    "\n",
    "    # decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu',\n",
    "                   padding='same')(conv3)  # 7 x 7 x 128\n",
    "    up1 = UpSampling2D((2, 2))(conv4)  # 14 x 14 x 128\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu',\n",
    "                   padding='same')(up1)  # 14 x 14 x 64\n",
    "    up2 = UpSampling2D((2, 2))(conv5)  # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid',\n",
    "                     padding='same')(up2)  # 28 x 28 x 1\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer=RMSprop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m577\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,625</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m314,625\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">314,625</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m314,625\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 62ms/step - loss: 0.0765 - val_loss: 0.0164\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 64ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 63ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 65ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 64ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 64ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 61ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 61ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "\u001b[1m 84/375\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - loss: 0.0036"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m autoencoder_train \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mfit(train_X, train_ground, batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      2\u001b[0m                                     epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(valid_X, valid_ground))\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 323\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    325\u001b[0m         step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    878\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\ai\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,\n",
    "                                    epochs=epochs, verbose=1, validation_data=(valid_X, valid_ground))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[39m=\u001b[39m autoencoder_train\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m val_loss \u001b[39m=\u001b[39m autoencoder_train\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(epochs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'autoencoder_train' is not defined"
     ]
    }
   ],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16b5ba8b0fc2955b30e9dcc40d80a15055b56bf6ee36ea534159a7d87da288cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
